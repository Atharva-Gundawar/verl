program: verl.trainer.fsdp_sft_trainer
method: bayes
metric:
  name: val/loss
  goal: minimize
command:
  - ${env}
  - torchrun
  - --standalone
  - --nproc_per_node=4
  - --nnodes=1
  - ${program}
  - ${args}
parameters:
  data.micro_batch_size_per_gpu:
    values: 4
  data.train_batch_size:
    values: [512, 1024, 2048]
  optim.lr:
    min: 1e-5
    max: 5e-3
    distribution: log_uniform
  model.enable_gradient_checkpointing:
    value: True
  trainer.total_epochs:
    value: 16
  data.max_length:
    value: 16384
  data.train_files:
    value: /verl_repo/data/astar/train_30x30_50k.parquet
  data.val_files:
    value: /verl_repo/data/astar/test_30x30.parquet
  data.prompt_key:
    value: extra_info
  data.prompt_dict_keys:
    value: 'question'
  data.response_key:
    value: extra_info
  data.response_dict_keys:
    value: 'answer'
  model.partial_pretrain:
    value: /verl_repo/data/models/pythia-14m-16k
  trainer.default_local_dir:
    value: /verl_repo/checkpoints/pythia-astar/pythia-14m-16k/
  trainer.default_hdfs_dir:
    value: hdfs://user/verl/experiments/astar/pythia-14m-16k/
  trainer.project_name:
    value: pythia-astar-sweep
  trainer.experiment_name:
    value: pythia-astar-14m-16k-sweep
  trainer.logger:
    value: ['console', 'wandb']
  trainer.resume_mode:
    value: auto
  trainer.save_freq:
    value: 10